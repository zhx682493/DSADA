import numpy as np
import pickle
import time

import logging
from sklearn import metrics
from sklearn.neighbors import KNeighborsClassifier
# from model.mapping import Mapping
import loss_function
from torch.autograd import Variable
from torch.utils.tensorboard import SummaryWriter
import utils
from utils import get_HBKC_data_loader, Task
# from utils import utils, loss_function, data_augment
import torch.nn as nn
import torch.nn.functional as F
import torch
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
from einops import rearrange
import os
import argparse
import math
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
parser = argparse.ArgumentParser(description="Few Shot Visual Recognition")
parser.add_argument("-f", "--feature_dim", type=int, default=100)
parser.add_argument("-c", "--src_input_dim", type=int, default=128)
# parser.add_argument("-MM", "--model_file", type=str, default='E:\zhx\my_new\MY2\pre_dino_CKS.pth')

parser.add_argument("-n", "--n_dim", type=int, default=100)
parser.add_argument("-z", "--test_lsample_num_per_class", type=int, default=5, help='5 4 3 2 1')
parser.add_argument("-s", "--shot_num_per_class", type=int, default=1)
parser.add_argument("-b", "--query_num_per_class", type=int, default=19)
parser.add_argument("-e", "--episode", type=int, default=5000)
parser.add_argument("-t", "--test_episode", type=int, default=600)
parser.add_argument("-l", "--learning_rate", type=float, default=0.01)
parser.add_argument("-g", "--gpu", type=int, default=0)
parser.add_argument("-u", "--hidden_unit", type=int, default=10)
parser.add_argument("-d", "--tar_input_dim", type=int, default=200)  # salinas=204;pc=102,ip=200
parser.add_argument("-w", "--class_num", type=int, default=16)
# parser.add_argument("-tm", "--tar_class_dim", type=int, default=16)
parser.add_argument("-m", "--test_class_num", type=int, default=16)
parser.add_argument('--alpha', default=0.9, type=float)
parser.add_argument('--pseudo_label_weight', default="prob")
parser.add_argument('--mask_block_size', default=32, type=int)
parser.add_argument('--mask_ratio', default=0.3, type=float)
parser.add_argument('--mask_color_jitter_s', default=0.2, type=float)
parser.add_argument('--mask_color_jitter_p', default=0.2, type=float)
parser.add_argument('--mask_blur', default=True, type=bool)
parser.add_argument('--norm-mean', type=float, nargs='+',
                    default=(0.485, 0.456, 0.406), help='normalization mean')
parser.add_argument('--norm-std', type=float, nargs='+',
                    default=(0.229, 0.224, 0.225), help='normalization std')

parser.add_argument('-i', '--iters-per-epoch', default=1000, type=int,
                    help='Number of iterations per epoch')
# mask settings

args = parser.parse_args(args=[])

os.environ["CUDA_VISIBLE_DEVICES"] = "1"

# seeds = [1236, 1237, 1240, 1222, 1223]

seeds = [1337,1236,1240,1235,1212]
# num_classes = 18
# N_BANDS = 128
# HalfWidth = args.halfwidth
patch_size = 9
# Hyper Parameters
# MODEL_FILE = args.model_file
FEATURE_DIM = args.feature_dim  # 160
SRC_INPUT_DIMENSION = args.src_input_dim  # 128
TAR_INPUT_DIMENSION = args.tar_input_dim
N_DIMENSION = args.n_dim  # 100
CLASS_NUM = args.class_num  # 16
SHOT_NUM_PER_CLASS = args.shot_num_per_class  # 1
QUERY_NUM_PER_CLASS = args.query_num_per_class  # 9
EPISODE = args.episode  # 20000
TEST_EPISODE = args.test_episode  # 600
LEARNING_RATE = args.learning_rate  # 0.001
GPU = args.gpu  # 0
HIDDEN_UNIT = args.hidden_unit  # 10
# TAR_CLASS_NUM = args.tar_class_dim
TAR_LSAMPLE_NUM_PER_CLASS = args.test_lsample_num_per_class
# BATCH_SIZE = 32
# Hyper Parameters in target domain data set
TEST_CLASS_NUM = args.test_class_num  # the number of class
TEST_LSAMPLE_NUM_PER_CLASS = args.test_lsample_num_per_class  # the number of labeled samples per class 5 4 3 2 1



# IP
labels_tar = ["Alfalfa", "Corn notill", "Corn mintill", "Corn", "Grass pasture", "Grass trees", "Grass pasture mowed",
              "Hay windrowed", "Oats", "Soybean notill", "Soybean mintill", "Soybean clean", "Wheat", "Woods",
              "Buildings Grass Trees Drives", "Stone Steel Towers"]

# houston
# labels_tar = ["Healthy grass", "Stressed grass", "Synthetic grass", "Trees", "Soil", "Water", "Residential", "Commercial", "Road", "Highway", "Railway", "Parking Lot 1", "Parking Lot 2", "Tennis Court", "Running Track"]

# salinas
# labels_tar = ["Brocoli green weeds 1", "Brocoli green weeds 2", "Fallow", "Fallow rough plow", "Fallow smooth", "Stubble", "Celery", "Grapes untrained", "Soil vinyard develop", "Corn senesced green weeds","Lettuce romaine 4wk", "Lettuce romaine 5wk", "Lettuce romaine 6wk", "Lettuce romaine 7wk" , "Vinyard untrained", "Vinyard vertical trellis"]

# longkou
# labels_tar = ["Corn", "Cotton", "Sesame", "Broad-leaf soybean", "Narrow-leaf soybean", "Rice", "Water", "Roads and houses", "Mixed weed"]


import clip

model, preprocess = clip.load('ViT-B/16', device=device)

model.eval()


def encode_text(texts, model):
    # 预处理文本并进行编码
    text_inputs = clip.tokenize(texts).to(device)  # CLIP的tokenize会处理分词
    with torch.no_grad():  # 确保不计算梯度
        text_features = model.encode_text(text_inputs)  # 获取文本特征
    return text_features


# 示例文本

# 获取源文本和目标文本的语义映射
# semantic_mapping_src = encode_text(labels_src, model)
semantic_mapping_tar = encode_text(labels_tar, model)

# 将语义映射转换为NumPy数组
# semantic_mapping_src = semantic_mapping_src.cpu().numpy()
semantic_mapping_tar = semantic_mapping_tar.cpu().numpy()

# print("Source semantic mappings:", semantic_mapping_src.shape)
print("Target semantic mappings:", semantic_mapping_tar.shape)

# load source domain data
with open(os.path.join('E:\zhx\HyMuT-master11\datasets', 'Chikusei_imdb_128.pickle'), 'rb') as handle:
    source_imdb = pickle.load(handle)

data_train = source_imdb['data']
labels_train = source_imdb['Labels']

keys_all_train = sorted(list(set(labels_train)))
label_encoder_train = {}
for i in range(len(keys_all_train)):
    label_encoder_train[keys_all_train[i]] = i
train_dict = {}
for class_, path in zip(labels_train, data_train):
    if label_encoder_train[class_] not in train_dict:
        train_dict[label_encoder_train[class_]] = []
    train_dict[label_encoder_train[class_]].append(path)
del keys_all_train
del label_encoder_train

metatrain_data = utils.sanity_check(train_dict)

for class_ in metatrain_data:
    for i in range(len(metatrain_data[class_])):
        metatrain_data[class_][i] = np.transpose(metatrain_data[class_][i], (2, 0, 1))
data_path = 'datasets'
target_data= 'IP/indian_pines_corrected.mat'
target_data_gt = 'IP/indian_pines_gt.mat'
log_dir = './logs'
# load target data
test_data = os.path.join(data_path, target_data)
test_label = os.path.join(data_path, target_data_gt)
Data_Band_Scaler, GroundTruth = utils.load_data(test_data, test_label)

def get_train_test_loader(Data_Band_Scaler, GroundTruth, class_num, shot_num_per_class):
    print(Data_Band_Scaler.shape) #  (145, 145, 200)
    [nRow, nColumn, nBand] = Data_Band_Scaler.shape

    '''label start'''
    num_class = int(np.max(GroundTruth))
    data_band_scaler = utils.flip(Data_Band_Scaler)#435*435*200
    groundtruth = utils.flip(GroundTruth)#435*435*200
    del Data_Band_Scaler
    del GroundTruth

    HalfWidth = 4
    G = groundtruth[nRow - HalfWidth:2 * nRow + HalfWidth, nColumn - HalfWidth:2 * nColumn + HalfWidth]  #裁剪为9*9的图像
    data = data_band_scaler[nRow - HalfWidth:2 * nRow + HalfWidth, nColumn - HalfWidth:2 * nColumn + HalfWidth,:]

    [Row, Column] = np.nonzero(G)  # (10249,) (10249,)
    # print(Row)
    del data_band_scaler
    del groundtruth

    nSample = np.size(Row)
    print('number of sample', nSample)  #10249

    # Sampling samples
    train = {}
    test = {}
    da_train = {} # Data Augmentation
    m = int(np.max(G))  # 16
    print('m=',m)
    nlabeled =TEST_LSAMPLE_NUM_PER_CLASS  #5
    print('labeled number per class:', nlabeled) #5
    print((200 - nlabeled) / nlabeled + 1)   #40
    print(math.ceil((200 - nlabeled) / nlabeled) + 1)  #40

    for i in range(m):  #遍历每个类别
        indices = [j for j, x in enumerate(Row.ravel().tolist()) if G[Row[j], Column[j]] == i + 1]  #按照G[Row[j], Column[j]] == i + 1条件筛选索引
        np.random.shuffle(indices)#随机打乱
        nb_val = shot_num_per_class
        train[i] = indices[:nb_val] #在每类选择5个样本构成训练集   16*5
        #print('train',train)
        da_train[i] = []
        for j in range(math.ceil((200 - nlabeled) / nlabeled) + 1):#0~39
            da_train[i] += indices[:nb_val]#重复每一类的样本并累加  5*40*16
        #print('da_train',da_train)  #5*40*16个样本
        test[i] = indices[nb_val:] #剩下的为测试集

    train_indices = []
    test_indices = []
    da_train_indices = []
    for i in range(m):
        train_indices += train[i]
        test_indices += test[i]
        da_train_indices += da_train[i]
    np.random.shuffle(test_indices)

    print('the number of train_indices:', len(train_indices))  # 80=16*5
    print('the number of test_indices:', len(test_indices))  # 10169=10249-80
    print('the number of train_indices after data argumentation:', len(da_train_indices))  # 3200
    print('labeled sample indices:',train_indices)

    nTrain = len(train_indices)  #80
    nTest = len(test_indices)#10169
    da_nTrain = len(da_train_indices)#3200

    imdb = {}
    imdb['data'] = np.zeros([2 * HalfWidth + 1, 2 * HalfWidth + 1, nBand, nTrain + nTest], dtype=np.float32)  # (9,9,100,n)
    imdb['Labels'] = np.zeros([nTrain + nTest], dtype=np.int64)
    imdb['set'] = np.zeros([nTrain + nTest], dtype=np.int64)

    RandPerm = train_indices + test_indices

    RandPerm = np.array(RandPerm)

    for iSample in range(nTrain + nTest):#截取数据  12049 9*9
        imdb['data'][:, :, :, iSample] = data[Row[RandPerm[iSample]] - HalfWidth:  Row[RandPerm[iSample]] + HalfWidth + 1,
                                         Column[RandPerm[iSample]] - HalfWidth: Column[RandPerm[iSample]] + HalfWidth + 1, :]
        imdb['Labels'][iSample] = G[Row[RandPerm[iSample]], Column[RandPerm[iSample]]].astype(np.int64)

    imdb['Labels'] = imdb['Labels'] - 1  # 1-16 0-15
    imdb['set'] = np.hstack((np.ones([nTrain]), 3 * np.ones([nTest]))).astype(np.int64)
    print('Data is OK.')

    train_dataset = utils.matcifar(imdb, train=True, d=3, medicinal=0)
    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=class_num * shot_num_per_class,shuffle=False, num_workers=0)
    print('train_dataset',len(train_dataset))#80
    del train_dataset

    test_dataset = utils.matcifar(imdb, train=False, d=3, medicinal=0)
    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=0)
    del test_dataset
    del imdb

    # Data Augmentation for target domain for training
    imdb_da_train = {}
    imdb_da_train['data'] = np.zeros([2 * HalfWidth + 1, 2 * HalfWidth + 1, nBand, da_nTrain],  dtype=np.float32)  # (9,9,100,n)
    imdb_da_train['Labels'] = np.zeros([da_nTrain], dtype=np.int64)
    imdb_da_train['set'] = np.zeros([da_nTrain], dtype=np.int64)

    da_RandPerm = np.array(da_train_indices)
    for iSample in range(da_nTrain):  # radiation_noise，flip_augmentation 截取数据3200  9*9
        imdb_da_train['data'][:, :, :, iSample] = utils.radiation_noise(
            data[Row[da_RandPerm[iSample]] - HalfWidth:  Row[da_RandPerm[iSample]] + HalfWidth + 1,
            Column[da_RandPerm[iSample]] - HalfWidth: Column[da_RandPerm[iSample]] + HalfWidth + 1, :])
        imdb_da_train['Labels'][iSample] = G[Row[da_RandPerm[iSample]], Column[da_RandPerm[iSample]]].astype(np.int64)

    imdb_da_train['Labels'] = imdb_da_train['Labels'] - 1  # 1-16 0-15
    imdb_da_train['set'] = np.ones([da_nTrain]).astype(np.int64)
    print('ok')

    return train_loader, test_loader, imdb_da_train ,G,RandPerm,Row, Column,nTrain
            #80           11069        3200       12049 12049               80


def get_target_dataset(Data_Band_Scaler, GroundTruth, class_num, shot_num_per_class):
    train_loader, test_loader, imdb_da_train,G,RandPerm,Row, Column,nTrain = get_train_test_loader(Data_Band_Scaler=Data_Band_Scaler,  GroundTruth=GroundTruth, \
                                                                     class_num=class_num,shot_num_per_class=shot_num_per_class)  # 9 classes and 5 labeled samples per class
    train_datas, train_labels = train_loader.__iter__().__next__()
    print('train labels:', train_labels)#16类，每类5个
    print('size of train datas:', train_datas.shape) # 80*200*9*9

    print(imdb_da_train.keys())
    print(imdb_da_train['data'].shape)  # 9*9*200*3200
    print(imdb_da_train['Labels'])
    del Data_Band_Scaler, GroundTruth

    # target data with data augmentation
    target_da_datas = np.transpose(imdb_da_train['data'], (3, 2, 0, 1))  # (9,9,100, 1800)->(1800, 100, 9, 9)
    print(target_da_datas.shape) #9*9*200*3200
    target_da_labels = imdb_da_train['Labels']  #3200
    print('target data augmentation label:', target_da_labels)

    # metatrain data for few-shot classification
    target_da_train_set = {}
    for class_, path in zip(target_da_labels, target_da_datas):
        if class_ not in target_da_train_set:
            target_da_train_set[class_] = []
        target_da_train_set[class_].append(path)
        #print('target_da_train_set', len(target_da_train_set))
    target_da_metatrain_data = target_da_train_set
    #print('target_da_metatrain_data',len(target_da_metatrain_data))
    print(target_da_metatrain_data.keys())

    # target domain : batch samples for domian adaptation
    print(imdb_da_train['data'].shape)  # (9, 9, 100, 225)
    print(imdb_da_train['Labels'])
    target_dataset = utils.matcifar(imdb_da_train, train=True, d=3, medicinal=0)
    target_loader = torch.utils.data.DataLoader(target_dataset, batch_size=128, shuffle=True, num_workers=0)#,drop_last=True)
    del target_dataset

    return train_loader, test_loader, target_da_metatrain_data, target_loader,G,RandPerm,Row, Column,nTrain
# model

class SpatialSE(nn.Module):
    # 定义各个层的部分
    def __init__(self,in_channel,out_channel):
        super(SpatialSE, self).__init__()
        self.conv = nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=1, padding=1)

    def forward(self, x):
        C = x.shape[1]
        x = self.conv(x)
        x = torch.sigmoid(x)
        out = x.repeat(1,C,1,1)
        return out
# patch size 7
class SpectralSE(nn.Module):
    # 定义各个层的部分
    def __init__(self, in_channel, C, sz):
        super(SpectralSE, self).__init__()
        # 全局池化
        self.avgpool = nn.AvgPool2d((sz, sz))
        self.conv1 = nn.Conv2d(in_channel, C//4, kernel_size=3, stride=1, padding=3)
        self.conv2 = nn.Conv2d(C//4, C, kernel_size=3, stride=1, padding=2)

    def forward(self, x):
        x = self.avgpool(x)
        x = self.conv1(x)
        x = F.relu(x)
        x = self.conv2(x)
        out = torch.sigmoid(x)
        return out



class DomainClassifier(nn.Module):
    def __init__(self):
        super(DomainClassifier, self).__init__()
        self.layer = nn.Sequential(
            nn.Linear(1024, 1024),
            nn.ReLU(),
            nn.Dropout(0.5),

            nn.Linear(1024, 1024),
            nn.ReLU(),
            nn.Dropout(0.5),

            nn.Linear(1024, 256),
            nn.ReLU(),
            nn.Dropout(0.5),

        )
        self.domain = nn.Linear(256, 1)
        self.layer0 = nn.Linear(152, 1024)

    def forward(self, x, iter_num=0):
        x = self.layer0(x)
        x = self.layer(x)
        domain_y = self.domain(x)
        return domain_y

from torchsummary import summary

"""
# Assuming SSSE_test is your model
model = SSSE_test(SRC_INPUT_DIMENSION=SRC_INPUT_DIMENSION,
                  TAR_INPUT_DIMENSION=TAR_INPUT_DIMENSION,
                  patch_size=patch_size,
                  n_classes=CLASS_NUM).to(device)

# Example input size: (number of channels, height, width)
input_size = (200,9,9)  # Modify based on your data dimensions

# Pass the model and input_size to summary
from torchsummary import summary
summary(model, input_size=input_size)
"""

def build_class_reps_and_covariance_estimates(context_features, context_labels):
    class_representations = {}
    class_precision_matrices = {}
    task_covariance_estimate = estimate_cov(
        context_features)  # 估计给定上下文特征 context_features 的协方差矩阵，并将结果存储在 task_covariance_estimate 变量中
    for c in torch.unique(context_labels):  # 迭代遍历上下文标签 context_labels 中唯一的类别
        # filter out feature vectors which have class c
        class_mask = torch.eq(context_labels, c)  # 创建了一个布尔张量 class_mask，用于过滤出与当前类别 c 对应的特征向量
        class_mask_indices = torch.nonzero(class_mask)  # 到了满足类别条件的特征向量的索引
        class_features = torch.index_select(context_features, 0,
                                            torch.reshape(class_mask_indices, (-1,)).to(device))  # 根据索引选择了满足类别条件的特征向量
        # mean pooling examples to form class means
        class_rep = mean_pooling(class_features)  # 平均池化
        # updating the class representations dictionary with the mean pooled representation
        class_representations[c.item()] = class_rep
        """
        Calculating the mixing ratio lambda_k_tau for regularizing the class level estimate with the task level estimate."
        Then using this ratio, to mix the two estimate; further regularizing with the identity matrix to assure invertability, and then
        inverting the resulting matrix, to obtain the regularized precision matrix. This tensor is then saved in the corresponding
        dictionary for use later in infering of the query data points.
        """
        lambda_k_tau = (class_features.size(0) / (
                    class_features.size(0) + 1))  # 计算了混合比例 lambda_k_tau，用于将类别级别的估计与任务级别的估计进行混合
        class_precision_matrices[c.item()] = torch.inverse(
            (lambda_k_tau * estimate_cov(class_features)) + ((1 - lambda_k_tau) * task_covariance_estimate) \
            + torch.eye(class_features.size(1), class_features.size(1)).to(device))  # 计算并存储了正则化后的精度矩阵
    return class_representations, class_precision_matrices


def mean_pooling(x):
    return torch.mean(x, dim=0, keepdim=True)


def estimate_cov(examples, rowvar=False, inplace=False):
    if examples.dim() > 2:
        raise ValueError('m has more than 2 dimensions')
    if examples.dim() < 2:
        examples = examples.view(1, -1)
    if not rowvar and examples.size(0) != 1:
        examples = examples.t()
    factor = 1.0 / (examples.size(1) - 1)
    if inplace:
        examples -= torch.mean(examples, dim=1, keepdim=True)
    else:
        examples = examples - torch.mean(examples, dim=1, keepdim=True)
    examples_t = examples.t()
    return factor * examples.matmul(examples_t).squeeze()


def MD_distance(support_feature, support_labels, query_features):
    NUM_SAMPLES = 1
    class_representations, class_precision_matrices = build_class_reps_and_covariance_estimates(support_feature,
                                                                                                support_labels)

    class_means = torch.stack(list(class_representations.values())).squeeze(1)
    class_precision_matrices = torch.stack(list(class_precision_matrices.values()))

    # grabbing the number of classes and query examples for easier use later in the function
    number_of_classes = class_means.size(0)
    number_of_targets = query_features.size(0)

    repeated_target = query_features.repeat(1, number_of_classes).view(-1, class_means.size(1))
    repeated_class_means = class_means.repeat(number_of_targets, 1)
    repeated_difference = (repeated_class_means - repeated_target)
    repeated_difference = repeated_difference.view(number_of_targets, number_of_classes,
                                                   repeated_difference.size(1)).permute(1, 0, 2)
    first_half = torch.matmul(repeated_difference, class_precision_matrices)
    sample_logits = torch.mul(first_half, repeated_difference).sum(dim=2).transpose(1, 0) * -1

    # return split_first_dim_linear(sample_logits, [NUM_SAMPLES, query_features.shape[0]])
    return sample_logits


def MD_distance_test1(support_feature, support_labels, query_features):
    NUM_SAMPLES = 1
    class_representations, class_precision_matrices = build_class_reps_and_covariance_estimates(support_feature,
                                                                                                support_labels)

    class_means = torch.stack(list(class_representations.values())).squeeze(1)
    class_precision_matrices = torch.stack(list(class_precision_matrices.values()))

    # grabbing the number of classes and query examples for easier use later in the function
    number_of_classes = class_means.size(0)
    number_of_targets = query_features.size(0)

    repeated_target = query_features.repeat(1, number_of_classes).view(-1, class_means.size(1))
    repeated_class_means = class_means.repeat(number_of_targets, 1)
    repeated_difference = (repeated_class_means - repeated_target)
    repeated_difference = repeated_difference.view(number_of_targets, number_of_classes,
                                                   repeated_difference.size(1)).permute(1, 0, 2)
    first_half = torch.matmul(repeated_difference, class_precision_matrices)
    sample_logits = torch.mul(first_half, repeated_difference).sum(dim=2).transpose(1, 0) * -1

    # return split_first_dim_linear(sample_logits, [NUM_SAMPLES, query_features.shape[0]])
    return sample_logits, class_representations, class_precision_matrices


def MD_distance_test2(query_features, class_representations, class_precision_matrices):
    # class_representations, class_precision_matrices = build_class_reps_and_covariance_estimates(support_feature, support_labels)
    #
    class_means = torch.stack(list(class_representations.values())).squeeze(1)
    # class_precision_matrices = torch.stack(list(class_precision_matrices.values()))
    #
    # # grabbing the number of classes and query examples for easier use later in the function
    number_of_classes = class_means.size(0)
    number_of_targets = query_features.size(0)

    repeated_target = query_features.repeat(1, number_of_classes).view(-1, query_features.size(1))
    repeated_class_means = class_means.repeat(number_of_targets, 1)
    repeated_difference = (repeated_class_means - repeated_target)
    repeated_difference = repeated_difference.view(number_of_targets, number_of_classes,
                                                   repeated_difference.size(1)).permute(1, 0, 2)
    first_half = torch.matmul(repeated_difference, class_precision_matrices)
    sample_logits = torch.mul(first_half, repeated_difference).sum(dim=2).transpose(1, 0) * -1

    return sample_logits
# loss init
crossEntropy = nn.CrossEntropyLoss().to(device)
cos_criterion = nn.CosineSimilarity(dim=1).to(device)
infoNCE_Loss = loss_function.ContrastiveLoss1(batch_size=CLASS_NUM).to(device)
# infoNCE_Loss = loss_function.ContrastiveLoss(batch_size=CLASS_NUM).to(device)
# infoNCE_Loss_SSL = loss_function.ContrastiveLoss(batch_size=128).to(GPU)
# SupConLoss_t = loss_function.SupConLoss(temperature=0.1).to(GPU)
criterion_domain = torch.nn.BCEWithLogitsLoss().to(device)
# experimental result index
nDataSet = 5
acc = np.zeros([nDataSet, 1])
A = np.zeros([nDataSet,CLASS_NUM])
k = np.zeros([nDataSet, 1])
best_predict_all = []
best_G, best_RandPerm, best_Row, best_Column, best_nTrain = None, None, None, None, None



# log setting
experimentSetting = '{}way_{}shot_entropy_loss_yuxian_{}'.format(CLASS_NUM, TAR_LSAMPLE_NUM_PER_CLASS, target_data.split('/')[0])
utils.set_logging_config(os.path.join(log_dir, experimentSetting), nDataSet)
logger = logging.getLogger('main')
logger.info('seeds_list:{}'.format(seeds))

def get_parameter_number(net):
    total_num = sum(p.numel() for p in net.parameters())
    trainable_num = sum(p.numel() for p in net.parameters() if p.requires_grad)
    return {'Total': total_num, 'Trainable': trainable_num}


for iDataSet in range(nDataSet):
    logger.info('emb_size:{}'.format(N_DIMENSION))
    logger.info('patch_size:{}'.format(patch_size))
    logger.info('seeds:{}'.format(seeds[iDataSet]))

    utils.same_seeds(seeds[iDataSet])

    # load target domain data for training and testing
    train_loader, test_loader, target_da_metatrain_data, target_loader,G,RandPerm,Row, Column,nTrain = get_target_dataset(
        Data_Band_Scaler=Data_Band_Scaler, GroundTruth=GroundTruth,class_num=TEST_CLASS_NUM, shot_num_per_class=TEST_LSAMPLE_NUM_PER_CLASS)


    feature_encoder = SSSE_test(SRC_INPUT_DIMENSION=SRC_INPUT_DIMENSION,TAR_INPUT_DIMENSION=TAR_INPUT_DIMENSION, patch_size=patch_size,n_classes=CLASS_NUM)# 提取特征

    feature_encoder.to(device)
    print(get_parameter_number(feature_encoder))
    feature_encoder.apply(utils.weights_init)
    # feature_encoder.load_state_dict(new_state_dict, strict=False)
    # feature_encoder.load_state_dict(torch.load('pre_dino_CKS.pth'))
    domain_classifier = DomainClassifier().to(device)
    text_encoder = WordEmbTransformers(feature_dim=152, dropout=0.5).to(device)

    encoder_optim = torch.optim.SGD(feature_encoder.parameters(),lr=args.learning_rate)
    domain_classifier_optim = torch.optim.Adam(domain_classifier.parameters(), lr=args.learning_rate)
    text_optim = torch.optim.Adam(text_encoder.parameters(), lr=args.learning_rate)

    logger.info("Training...")
    last_accuracy = 0.0
    best_episode = 0

    total_hit_src, total_num_src, total_hit_tar, total_num_tar, acc_src, acc_tar = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0

    train_start = time.time()
    writer = SummaryWriter()


    for episode in range(EPISODE):
        # source and target few-shot learning
        task_src = Task(metatrain_data, CLASS_NUM, SHOT_NUM_PER_CLASS, QUERY_NUM_PER_CLASS)
        support_dataloader_src = get_HBKC_data_loader(task_src, num_per_class=SHOT_NUM_PER_CLASS, split="train",shuffle=False)
        query_dataloader_src = get_HBKC_data_loader(task_src, num_per_class=QUERY_NUM_PER_CLASS, split="test",shuffle=False)

        task_tar = Task(target_da_metatrain_data,CLASS_NUM, SHOT_NUM_PER_CLASS, QUERY_NUM_PER_CLASS)
        support_dataloader_tar = get_HBKC_data_loader(task_tar, num_per_class=SHOT_NUM_PER_CLASS, split="train",shuffle=False)
        query_dataloader_tar = get_HBKC_data_loader(task_tar, num_per_class=QUERY_NUM_PER_CLASS, split="test",shuffle=False)

        support_src, support_label_src = support_dataloader_src.__iter__().next()
        query_src, query_label_src = query_dataloader_src.__iter__().next()

        feature_encoder.train()
        domain_classifier.train()
        text_encoder.train()

        total_hit_src += torch.sum(torch.argmax(logits_src, dim=1).cpu() == query_label_src).item()
        total_num_src += query_src.shape[0]
        acc_src = total_hit_src / total_num_src

        total_hit_tar += torch.sum(torch.argmax(logits_tar, dim=1).cpu() == query_label_tar).item()
        total_num_tar += query_tar.shape[0]
        acc_tar = total_hit_tar / total_num_tar

        if (episode + 1) % 100 == 0:
            logger.info(
                'episode: {:>3d}, f_loss_tar: {:6.4f}, f_loss_src: {:6.4f}, text_align_loss:{:6.4f}, loss_entropy:{:6.4f},loss: {:6.4f}, acc_src: {:6.4f}, acc_tar: {:6.4f}'.format(
                    episode + 1,
                    f_loss_tar.item(),f_loss_src.item(),
                    text_align_loss.item(),
                    loss_entropy.item(),
                    loss.item(),
                    acc_src,
                    acc_tar))

            writer.add_scalar('Loss/f_loss_tar', f_loss_tar.item(), episode + 1)
            writer.add_scalar('Loss/f_loss_src', f_loss_src.item(), episode + 1)
            writer.add_scalar('Loss/text_align_loss', text_align_loss.item(), episode + 1)
            writer.add_scalar('Loss/loss_entropy', loss_entropy.item(), episode + 1)
            writer.add_scalar('Loss/loss', loss.item(), episode + 1)

            writer.add_scalar('Acc/acc_src', acc_src, episode + 1)
            writer.add_scalar('Acc/acc_tar', acc_tar, episode + 1)

        if (episode + 1) % 500 == 0 or episode == 0:
            # with torch.no_grad():
                # test
                logger.info("Testing ...")
                train_end = time.time()

                feature_encoder.eval()
                total_rewards = 0
                counter = 0
                accuracies = []
                predict = np.array([], dtype=np.int64)
                predict_gnn = np.array([], dtype=np.int64)
                labels = np.array([], dtype=np.int64)
                all_test_outputs = []
                all_test_labels = []
                train_datas, train_labels = train_loader.__iter__().next()


                train_features, _ = feature_encoder(Variable(train_datas).to(device),domain='target')

                flag = 1
                for test_datas, test_labels in test_loader:
                    batch_size = test_labels.shape[0]

                    test_features, test_outputs = feature_encoder(Variable(test_datas).cuda(), domain='target')  # (100, 160)
                    if flag == 1:
                        predict_logits, class_representations, class_precision_matrices = MD_distance_test1(
                            train_features,
                            train_labels,
                            test_features)
                    else:
                        predict_logits = MD_distance_test2(test_features, class_representations,
                                                           class_precision_matrices)
                    predict_labels = torch.argmax(predict_logits, dim=1).cpu()
                    test_labels = test_labels.numpy()
                    rewards = [1 if predict_labels[j] == test_labels[j] else 0 for j in range(batch_size)]
                    total_rewards += np.sum(rewards)
                    counter += batch_size

                    predict = np.append(predict, predict_labels)
                    labels = np.append(labels, test_labels)

                    accuracy = total_rewards / 1.0 / counter  #
                    accuracies.append(accuracy)
                    flag = flag + 1
                    # all_test_outputs.append(test_outputs.cpu())  # 使用 `.cpu()` 转换为 CPU 上的 tensor
                    # all_test_labels.append(test_labels)
                test_accuracy = 100. * total_rewards / len(test_loader.dataset)
                writer.add_scalar('Acc/acc_test', test_accuracy, episode + 1)

                logger.info('\t\tAccuracy: {}/{} ({:.2f}%)\n'.format(total_rewards, len(test_loader.dataset),
                                                                     100. * total_rewards / len(test_loader.dataset)))
                test_end = time.time()
                feature_encoder.train()
                if test_accuracy > last_accuracy:
                    last_accuracy = test_accuracy
                    best_episode = episode
                    acc[iDataSet] = 100. * total_rewards / len(test_loader.dataset)
                    OA = acc
                    C1 = metrics.confusion_matrix(labels, predict)
                    A[iDataSet, :] = np.diag(C1) / np.sum(C1, 1, dtype=float)
                    best_predict_all = predict
                    best_G, best_RandPerm, best_Row, best_Column, best_nTrain = G, RandPerm, Row, Column, nTrain
                    k[iDataSet] = metrics.cohen_kappa_score(labels, predict)

                logger.info('best episode:[{}], best accuracy={}'.format(best_episode + 1, last_accuracy))

    logger.info('iter:{} best episode:[{}], best accuracy={}'.format(iDataSet, best_episode + 1, last_accuracy))
    logger.info("train time per DataSet(s): " + "{:.5f}".format(train_end - train_start))
    logger.info("accuracy list: {}".format(acc))
    logger.info('***********************************************************************************')

OAMean = np.mean(acc)
OAStd = np.std(acc)

AA = np.mean(A, 1)
AAMean = np.mean(AA, 0)
AAStd = np.std(AA)

kMean = np.mean(k)
kStd = np.std(k)

AMean = np.mean(A, 0)
AStd = np.std(A, 0)

logger.info("train time per DataSet(s): " + "{:.5f}".format(train_end - train_start))
logger.info("test time per DataSet(s): " + "{:.5f}".format(test_end - train_end))
logger.info("average OA: " + "{:.2f}".format(OAMean) + " +- " + "{:.2f}".format(OAStd))
logger.info("average AA: " + "{:.2f}".format(100 * AAMean) + " +- " + "{:.2f}".format(100 * AAStd))
logger.info("average kappa: " + "{:.4f}".format(100 * kMean) + " +- " + "{:.4f}".format(100 * kStd))
logger.info("accuracy list: {}".format(acc))
logger.info("accuracy for each class: ")
for i in range(CLASS_NUM):
    logger.info("Class " + str(i) + ": " + "{:.2f}".format(100 * AMean[i]) + " +- " + "{:.2f}".format(100 * AStd[i]))

#################classification map################################
for i in range(len(best_predict_all)):
    best_G[best_Row[best_RandPerm[best_nTrain + i]]][best_Column[best_RandPerm[best_nTrain + i]]] = best_predict_all[
                                                                                                        i] + 1

hsi_pic = np.zeros((best_G.shape[0], best_G.shape[1], 3))
for i in range(best_G.shape[0]):
    for j in range(best_G.shape[1]):
        if best_G[i][j] == 0:
            hsi_pic[i, j, :] = [0, 0, 0]
        if best_G[i][j] == 1:
            hsi_pic[i, j, :] = [0, 0, 1]
        if best_G[i][j] == 2:
            hsi_pic[i, j, :] = [0, 1, 0]
        if best_G[i][j] == 3:
            hsi_pic[i, j, :] = [0, 1, 1]
        if best_G[i][j] == 4:
            hsi_pic[i, j, :] = [1, 0, 0]
        if best_G[i][j] == 5:
            hsi_pic[i, j, :] = [1, 0, 1]
        if best_G[i][j] == 6:
            hsi_pic[i, j, :] = [1, 1, 0]
        if best_G[i][j] == 7:
            hsi_pic[i, j, :] = [0.5, 0.5, 1]
        if best_G[i][j] == 8:
            hsi_pic[i, j, :] = [0.65, 0.35, 1]
        if best_G[i][j] == 9:
            hsi_pic[i, j, :] = [0.75, 0.5, 0.75]
        if best_G[i][j] == 10:
            hsi_pic[i, j, :] = [0.75, 1, 0.5]
        if best_G[i][j] == 11:
            hsi_pic[i, j, :] = [0.5, 1, 0.65]
        if best_G[i][j] == 12:
            hsi_pic[i, j, :] = [0.65, 0.65, 0]
        if best_G[i][j] == 13:
            hsi_pic[i, j, :] = [0.75, 1, 0.65]
        if best_G[i][j] == 14:
            hsi_pic[i, j, :] = [0, 0, 0.5]
        if best_G[i][j] == 15:
            hsi_pic[i, j, :] = [0, 1, 0.75]
        if best_G[i][j] == 16:
            hsi_pic[i, j, :] = [0.5, 0.75, 1]

halfwidth = patch_size // 2
utils.classification_map(hsi_pic[halfwidth:-halfwidth, halfwidth:-halfwidth, :],

                         best_G[halfwidth:-halfwidth, halfwidth:-halfwidth], 24,
                         "classificationMap/IP_loss_yuxian_{}shot_entropy.png".format(TAR_LSAMPLE_NUM_PER_CLASS))



